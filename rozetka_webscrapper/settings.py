# scrap setup. Estimated comments count == multiplication of next values below
COMMENTS_PER_PAGE_LIMIT = 30
ITEMS_PER_GROUP_LIMIT = 30
GROUPS_PER_CATEGORY_LIMIT = 10
CATEGORIES_LIMIT = 10

#Saving: Path & file templates
SITE_SCRAP_RESULT_FILE_NAME_PREFIX = 'results'
BOW_RESULT_FILE_NAME_PREFIX = 'bow'
BIGRAMM_RESULT_FILE_NAME_PREFIX = 'bigramm'

RESULT_FOLDER_NAME = "results"
RESULT_BOW_SUB_FOLDER_NAME = "bow"
RESULT_BIGRAMM_SUB_FOLDER_NAME = "bigramm"

SITE_SCRAP_RELATIVE_FILE_PATH_STRING = RESULT_FOLDER_NAME + "/" + SITE_SCRAP_RESULT_FILE_NAME_PREFIX + "_{}.json"
BOW_RELATIVE_FILE_PATH_STRING = RESULT_FOLDER_NAME + "/" + RESULT_BOW_SUB_FOLDER_NAME + "/" + BOW_RESULT_FILE_NAME_PREFIX + "_{}.json"
BIGRAMM_RELATIVE_FILE_PATH_STRING = RESULT_FOLDER_NAME + "/" + RESULT_BIGRAMM_SUB_FOLDER_NAME + "/" + BIGRAMM_RESULT_FILE_NAME_PREFIX + "_{}.json"

#Scrapper driver to render web pages with script driven UI
DEFAULT_SELENIUM_DRIVER = "Chrome"

#Application work mode
APPLICATION_MODE = "from_file"
APPLICATION_MODES_LIST = ["clean", "from_file"] #append new
#Post process work mode
POSTPROCESS_MODE = "word2vec"
POSTPROCESS_MODES_LIST = ["bow", "word2vec" ]
